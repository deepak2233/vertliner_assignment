{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define dataset path\n",
    "dataset_folder_path = 'data/Semantic segmentation dataset'\n",
    "\n",
    "# Class and color mapping\n",
    "color_to_class = {\n",
    "    (226, 169, 41): 0,  # Water\n",
    "    (132, 41, 246): 1,  # Land\n",
    "    (110, 193, 228): 2, # Road\n",
    "    (60, 16, 152): 3,   # Building\n",
    "    (254, 221, 58): 4,  # Vegetation\n",
    "    (155, 155, 155): 5  # Unlabeled\n",
    "}\n",
    "\n",
    "class_labels = ['Water', 'Land', 'Road', 'Building', 'Vegetation', 'Unlabeled']\n",
    "\n",
    "# Initialize variables for basic statistics\n",
    "total_images = 0\n",
    "total_masks = 0\n",
    "class_counts = np.zeros(len(class_labels), dtype=int)\n",
    "image_shapes = []\n",
    "\n",
    "# Function to count class pixels in a mask\n",
    "def count_class_pixels(mask_array):\n",
    "    counts = np.zeros(len(class_labels), dtype=int)\n",
    "    for rgb, class_idx in color_to_class.items():\n",
    "        match = np.all(mask_array == rgb, axis=-1)\n",
    "        counts[class_idx] += np.sum(match)\n",
    "    return counts\n",
    "\n",
    "# Function to load images and masks\n",
    "def load_images_and_masks(dataset_folder_path, image_size=(256, 256)):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for tile in os.listdir(dataset_folder_path):\n",
    "        tile_path = os.path.join(dataset_folder_path, tile)\n",
    "        if os.path.isdir(tile_path):\n",
    "            images_folder = os.path.join(tile_path, 'images')\n",
    "            masks_folder = os.path.join(tile_path, 'masks')\n",
    "            for image_file in os.listdir(images_folder):\n",
    "                img_path = os.path.join(images_folder, image_file)\n",
    "                mask_file = image_file.replace('.jpg', '.png')\n",
    "                mask_path = os.path.join(masks_folder, mask_file)\n",
    "                if os.path.exists(mask_path):\n",
    "                    image = Image.open(img_path).resize(image_size)\n",
    "                    mask = Image.open(mask_path).resize(image_size).convert('RGB')\n",
    "                    images.append(np.array(image) / 255.0)  # Normalize images\n",
    "                    masks.append(np.array(mask))\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Function to preprocess masks to one-hot encoding\n",
    "def preprocess_masks(masks, num_classes=6):\n",
    "    processed_masks = []\n",
    "    for mask in masks:\n",
    "        mask_class_indices = np.zeros(mask.shape[:2], dtype=int)\n",
    "        for rgb, class_idx in color_to_class.items():\n",
    "            match = np.all(mask == rgb, axis=-1)\n",
    "            mask_class_indices[match] = class_idx\n",
    "        mask_one_hot = to_categorical(mask_class_indices, num_classes=num_classes)\n",
    "        processed_masks.append(mask_one_hot)\n",
    "    return np.array(processed_masks)\n",
    "\n",
    "# Load and preprocess data\n",
    "print(\"Loading and preprocessing data...\")\n",
    "train_images_np, train_masks_np = load_images_and_masks(dataset_folder_path)\n",
    "train_masks_np = preprocess_masks(train_masks_np, num_classes=6)\n",
    "\n",
    "# Perform train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_images_np, test_images_np, train_masks_np, test_masks_np = train_test_split(train_images_np, train_masks_np, test_size=0.2, random_state=42)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Performing basic statistics...\")\n",
    "for mask in train_masks_np:\n",
    "    class_counts += np.sum(mask, axis=(0, 1)).astype(int)\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"Total Images: {len(train_images_np)}\")\n",
    "print(\"Class Distribution:\", {label: count for label, count in zip(class_labels, class_counts)})\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(class_labels, class_counts)\n",
    "plt.title(\"Class Distribution in the Dataset\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Pixel Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Visualize a few sample images and masks\n",
    "print(\"Visualizing sample images and masks...\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(train_images_np[i])\n",
    "    plt.title(\"Sample Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 5, i+6)\n",
    "    plt.imshow(np.argmax(train_masks_np[i], axis=-1), cmap='tab20')\n",
    "    plt.title(\"Segmentation Mask\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Advanced Data Augmentation\n",
    "data_gen_args = dict(\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "# ImageDataGenerator for images and masks\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Create data generators\n",
    "image_generator = image_datagen.flow(train_images_np, batch_size=4, seed=42)\n",
    "mask_generator = mask_datagen.flow(train_masks_np, batch_size=4, seed=42)\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "# Visualize augmented images and masks\n",
    "print(\"Visualizing augmented images and masks...\")\n",
    "augmented_images, augmented_masks = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(augmented_images[i])\n",
    "    plt.title(\"Augmented Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 4, i+5)\n",
    "    plt.imshow(np.argmax(augmented_masks[i], axis=-1), cmap='tab20')\n",
    "    plt.title(\"Augmented Mask\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Co-occurrence Analysis\n",
    "print(\"Performing class co-occurrence analysis...\")\n",
    "co_occurrence_matrix = np.zeros((len(class_labels), len(class_labels)), dtype=int)\n",
    "\n",
    "for mask in train_masks_np:\n",
    "    unique_classes = np.unique(np.argmax(mask, axis=-1))\n",
    "    for class_pair in combinations(unique_classes, 2):\n",
    "        co_occurrence_matrix[class_pair[0], class_pair[1]] += 1\n",
    "        co_occurrence_matrix[class_pair[1], class_pair[0]] += 1\n",
    "\n",
    "# Plot co-occurrence matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(co_occurrence_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title(\"Class Co-occurrence Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Object size and aspect ratio analysis\n",
    "print(\"Performing object size and aspect ratio analysis...\")\n",
    "object_sizes = {label: [] for label in class_labels}\n",
    "aspect_ratios = {label: [] for label in class_labels}\n",
    "\n",
    "for mask in train_masks_np:\n",
    "    for class_rgb, class_idx in color_to_class.items():\n",
    "        binary_mask = np.all(mask[:, :, :3] == class_rgb, axis=-1).astype(np.uint8)\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 10:  # Ignore very small areas\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                object_sizes[class_labels[class_idx]].append(area)\n",
    "                aspect_ratios[class_labels[class_idx]].append(w / h)\n",
    "\n",
    "# Plot object size distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "for label in class_labels:\n",
    "    plt.hist(object_sizes[label], bins=20, alpha=0.6, label=label)\n",
    "plt.title(\"Object Size Distribution by Class\")\n",
    "plt.xlabel(\"Object Size (Pixels)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot aspect ratio distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "for label in class_labels:\n",
    "    plt.hist(aspect_ratios[label], bins=20, alpha=0.6, label=label)\n",
    "plt.title(\"Object Aspect Ratio Distribution by Class\")\n",
    "plt.xlabel(\"Aspect Ratio (Width/Height)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
